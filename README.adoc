//
// Copyright (c) 2019, 2022 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:projectid: instanton-aws
:page-layout: guide-multipane
:page-duration: 45 minutes
:page-releasedate: 2023-07-06
:page-description: Learn how to deploy microservices in Open Liberty InstantOn container and enable IBM Semeru CloudCompiler to Amazon Elastic Kubernetes Service (EKS) on Amazon Web Services (AWS) to speed up the start-upprocess of your application.
:page-tags: ['Kubernetes', 'Podman', 'Semeru Cloud']
:page-permalink: /guides/{projectid}
:page-related-guides: ['kubernetes-intro', 'kubernetes-microprofile-config', 'kubernetes-microprofile-health', 'istio-intro']
:common-includes: https://raw.githubusercontent.com/OpenLiberty/guides-common/prod
:source-highlighter: prettify
:page-seo-title: Deploying Java microservices in Open Liberty InstantOn container to Amazon Elastic Kubernetes Service (AWSEKS) ) on Amazon Web Services (AWS)
:page-seo-description: A getting started tutorial with examples on how to deploy Java microservices in Open Liberty InstantOncontainer and enable IBM Semeru Cloud Compiler (SCC) to Amazon Elastic Kubernetes Service (EKS) onAmazon Web Services (AWS) by using Amazon Elastic Container Registry (ECR) as a private container registry.
:guide-author: Open Liberty
= Deploying a microservice to Amazon Web Services

Deploying a microservice in Open Liberty InstantOn container to Amazon Web Services

[.hidden]
NOTE: This repository contains the guide documentation source. To view the guide in published form, view it on the https://openliberty.io/guides/{projectid}.html[Open Liberty website^].
:kube: Kubernetes
:hashtag: #
:win: WINDOWS
:mac: MAC
:linux: LINUX
:system-api: http://[hostname]:31000/system/properties
:inventory-api: http://[hostname]:32000/inventory/systems


// =================================================================================================
// Introduction
// =================================================================================================

== What you'll learn

You will learn how to deploy system microservice in Open Liberty containers to a Kubernetes cluster on Amazon Elastic Container Service for Kubernetes (EKS). 

Amazon Web Services (AWS) offers a managed Kubernetes service called Amazon Elastic Container Service for kubernetes (EKS). EKS simplifies the process of running Kubernetes on AWS without needing to install or maintain your Kubernetes control plane. It provides a hosted kubernetes cluster where you can deploy your microservices. You will use EKS with Amazon Elastic Container Registry (ECR). Amazon ECR is a private registry that is used to store and distribute your container images. Note, because EKS is not free, there is a small cost that is associated with running this guide. See the official https://aws.amazon.com/eks/pricing/[Amazon EKS pricing^] documentation for more information.

Open Liberty InstantOn provides fast startup times for MicroProfile and Jakarta EE applications. With InstantOn, your applications can start in milliseconds, without compromising on throughput, memory, development-production parity, or Java language features.

The microservice you will deploy are called `system`. The `system` microservice returns the JVM system properties of the running container. It also returns the pod’s name in the HTTP header, making replicas easy to distinguish from each other. 

// =================================================================================================
// Prerequisites
// =================================================================================================

== Additional prerequisites

You must run this guide in a Linux environment.

Before you begin, the following additional tools need to be installed:

* *Linux:* You need to use kernel version of 5.9 or greater for Ubuntu or RHEL 9.0+ along with the X86-64/AMD64 processor.

* *Podman:* You need containerization software for building containers. Kubernetes supports various container types, but you will need the latest available version of Podman in this guide. For installation instructions, refer to the official https://podman.io/docs/installation documentation.

* *kubectl:* You need the Kubernetes command-line tool `kubectl` to interact with your Kubernetes cluster. See the official https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl[Install and Set Up kubectl^] documentation for information about downloading and setting up `kubectl` on your platform.

* *IAM Authenticator:* You need to install the AWS IAM Authenticator for Kubernetes to allow IAM authentication for your Amazon EKS cluster. Follow the https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html[Installing aws-iam-authenticator^] instructions to install the AWS IAM Authenticator on your platform. 

* *eksctl:* In this guide, you will need to use the `eksctl` Command Line Interface (CLI) tool for provisioning your EKS cluster. Navigate to the https://github.com/weaveworks/eksctl/releases[eksctl releases page^] and download the latest stable release. Extract the archive and add the directory with the extracted files to your path.

* *AWS CLI:* You will need to use the AWS Command Line Interface (CLI). For this guide, use AWS CLI Version 2, which is intended for use in production environment. All installers for AWS CLI version 2 include and use an embedded copy of Python, independent of any other Python version that you might have installed. Install the AWS CLI by following the instructions in the official https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html[Installing the AWS CLI^] documentation. 

// =================================================================================================
// Getting Started
// =================================================================================================

[role=command]
include::{common-includes}/gitclone.adoc[]

// no "try what you'll build" section in this guide because it would be too long due to all setup the user will have to do.

== Building the InstantOn image 

[#build]

Building the InstantOn image with Podman and the checkpoint.sh script

Navigate to the `start` directory. To build the WAR for the application run the following :

[role=command]
```
mvn package
```

The following image template example uses the `kernel-slim-java17-openj9-ubi` tag to build an image that uses the latest Open Liberty release with the IBM Semeru distribution of Java 17. 

[role="code_command hotspot file=0",subs="quotes"]
----
#Create the `Dockerfile`.#
`system/Dockerfile`
----

// File 0
Dockerfile
[source, text, linenums, role="code_column"]
----
include::finish/system/Dockerfile[]
----

You can use the `checkpoint.sh` script to perform the application checkpoint by adding the `RUN checkpoint.sh` instruction to the end of your `Dockerfile` or `Containerfile` file. The execution of the `checkpoint.sh` must be the last `RUN` instruction during your container image build. This configuration performs the application process checkpoint and stores the process data as the last layer of the application container image. Currently, this script requires you to use Podman rather than Docker because Docker cannot grant the necessary Linux capabilities. This example uses the `afterAppStart` checkpoint option. See https://openliberty.io/docs/latest/instanton.html#afterAppStart documentation for more information on `checkpoint.sh`. 

Use the following Podman command to build the InstantOn application container image. To grant the necessary Linux capabilities to the container image build, this command must be run either as the `root` user or by using the `sudo` utility.

[role=command]
----
podman build \
   -t dev.local/system:1.0-SNAPSHOT \
   --cap-add=CHECKPOINT_RESTORE \
   --cap-add=SYS_PTRACE\
   --cap-add=SETPCAP \
   --security-opt seccomp=unconfined system/.
----

The three `--cap-add` options grant the three Linux capabilities that CRIU requires to perform the application process checkpoint during the container image build. The `--security-opt` option grants access to all Linux system calls to the container image build.

When the build finishes, run the following command to list all local images:

[role=command]
```
podman images
```

Verify that the `system:1.0-SNAPSHOT` image is listed among them, for example:

[source, role="no_copy"]
----
REPOSITORY                        TAG
dev.local/system                  1.0-SNAPSHOT
icr.io/appcafe/open-liberty       kernel-slim-java11-openj9-ubi       
----

If you don't see the `system:1.0-SNAPSHOT` image, then check the Maven build log for any potential errors.

Running an InstantOn application image locally

If a host system is running the Linux kernel 5.9 or greater with the X86-64/AMD64 processor, you can run an InstantOn application image by using Podman or Docker locally. The following command runs the `system` InstantOn application image with Podman:

[role=command]
----
podman run \
  --rm \
  --cap-add=CHECKPOINT_RESTORE \
  --cap-add=SETPCAP \
  --security-opt seccomp=unconfined \
  -p 9080:9080 \
  system:1.0-SNAPSHOT
----

[source, role="no_copy"]
----
[AUDIT   ] CWWKF0011I: The defaultServer server is ready to run a smarter planet. The defaultServer server started in 0.298 seconds.
----

Notice that the startup time is less than 1 second. After you finish checking out the application, stop the Open Liberty server by pressing `CTRL+C` in the command-line session where you ran the server.

For more information on InstantOn application image, see https://openliberty.io/docs/latest/instanton.html.

// =================================================================================================
// Creating a Kubernetes cluster on EKS
// =================================================================================================

== Creating a Kubernetes cluster on EKS

Before you can deploy your microservices, you must create a Kubernetes cluster.

// =================================================================================================
// Configuring the AWS CLI
// =================================================================================================
=== Configuring the AWS CLI

Before you configure the AWS CLI, you need to create an AWS Identity and Access Management (IAM) user. Navigate to the https://console.aws.amazon.com/iam/home#/users[Identity and Access Management^] users dashboard and create a user through the UI. While creating a user, you must give the user `programmatic access` when selecting the AWS access type. You will also be prompted to add the user to a group. A group allows you to specify permissions for multiple users. If you do not have an existing group, you need to create a new one. Be sure to take note of the `AWS Access Key ID` and `AWS Secret Access Key`. After the AWS CLI is installed, it must be configured by running the AWS configure command. 

You will be prompted for several pieces of information, including an `AWS Access Key ID` and an `AWS Secret Access Key`. These keys are associated with the AWS Identity and Access Management (IAM) user that you created.

[role=command]
```
aws configure
```

Next, you will be prompted to enter a region. This region will be the region of the servers where your requests are sent. Select the region that is closest to you. For a full list of regions, see the https://docs.aws.amazon.com/general/latest/gr/rande.html#eks_region[AWS Regions and Endpoints^].

Finally, enter `json` when you are prompted to enter the output format. 

After you are done filling out this information, the settings are stored in the default profile. Anytime that you run an AWS CLI command without specifying a profile, the default profile is used. 

You can verify your current configuration values by running the following command: 
[role=command]
```
aws configure list
```

[source, role="no_copy"]
----
     Name                    Value             Type    Location
      ----                    -----             ----    --------
   profile                <not set>             None    None
access_key     ****************OABC shared-credentials-file    
secret_key     ****************ABc0 shared-credentials-file    
    region                us-east-2      config-file    ~/.aws/config
----

// =================================================================================================
// Provisioning a cluster
// =================================================================================================

=== Provisioning a cluster

The `eksctl` CLI tool greatly simplifies the process of creating clusters on EKS. To create your cluster, use the `eksctl create cluster` command:

[role=command]
```
eksctl create cluster --name=guide-cluster --nodes=1 --node-type=t2.small
```

Running this command creates a cluster that is called `guide-cluster` that uses a single `t2.small` Amazon Elastic Compute Cloud (EC2) instance as the worker node. The `t2.small` EC2 instance is not included in the AWS free tier. See the official https://aws.amazon.com/ec2/pricing/on-demand/[Amazon EC2 pricing^] documentation for more details. When the cluster is created, you see an output similar to the following:

[source, role="no_copy"]
```
[✔]  EKS cluster "guide-cluster" in "us-east-2" region is ready
```

After your cluster is ready, EKS connects `kubectl` to the cluster. Verify that you're connected to the cluster by checking the cluster's nodes:

[role=command]
```
kubectl get nodes
```

[source, role="no_copy"]
----
NAME                            STATUS    ROLES     AGE       VERSION
ip.us-east-2.compute.internal   Ready     <none>    7m        v1.11.5
----


// =================================================================================================
// Installing the Operator
// =================================================================================================

== Installing the Operator

// Static guide instruction
ifndef::cloud-hosted[]
Before you can deploy your microservice, you must install the https://cert-manager.io[cert-manager^] and the Open Liberty Operator. For more information, see the link:https://github.com/OpenLiberty/open-liberty-operator/tree/main/deploy/releases/1.2.0#readme[installation instructions].

First, install the cert-manager to your Kubernetes cluster by running the following command:
[role='command']
```
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.12.0/cert-manager.yaml
```


Next, install Custom Resource Definitions (CRDs) for the Open Liberty Operator by running the following command:
[role='command']
```
kubectl apply --server-side -f https://raw.githubusercontent.com/OpenLiberty/open-liberty-operator/main/deploy/releases/1.2.0/kubectl/openliberty-app-crd.yaml
```
Custom Resources extend the Kubernetes API and enhance its functionality.

Set environment variables for namespaces for the Operator by running the following commands:

[role='command']
```
OPERATOR_NAMESPACE=default
WATCH_NAMESPACE='""'
```

Next, run the following commands to install cluster-level role-based access:

[role='command']
```
curl -L https://raw.githubusercontent.com/OpenLiberty/open-liberty-operator/main/deploy/releases/1.2.0/kubectl/openliberty-app-rbac-watch-all.yaml \
  | sed -e "s/OPEN_LIBERTY_OPERATOR_NAMESPACE/${OPERATOR_NAMESPACE}/" \
  | kubectl apply -f -
```

Finally, run the following commands to install the Operator:

[role='command']
```
curl -L https://raw.githubusercontent.com/OpenLiberty/open-liberty-operator/main/deploy/releases/1.2.0/kubectl/openliberty-app-operator.yaml \
  | sed -e "s/OPEN_LIBERTY_WATCH_NAMESPACE/${WATCH_NAMESPACE}/" \
  | kubectl apply -n ${OPERATOR_NAMESPACE} -f -
```
endif::[]

// Cloud hosted guide instruction
ifdef::cloud-hosted[]
The Open Liberty Operator is already installed in this Skills Network environment. To learn how to install the Open Liberty Operator yourself, see the [Deploying microservices to OpenShift by using Kubernetes Operators](https://openliberty.io/guides/cloud-openshift-operator.html#installing-the-operators) guide or the [Open Liberty Operator documentation](https://github.com/OpenLiberty/open-liberty-operator/blob/main/doc/user-guide-v1.adoc#operator-installation).
endif::[]

To check that the Open Liberty Operator has been installed successfully, run the following command to view all the supported API resources that are available through the Open Liberty Operator:
[role='command']
```
kubectl api-resources --api-group=apps.openliberty.io
```

Look for the following output, which shows the https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/[custom resource definitions^] (CRDs) that can be used by the Open Liberty Operator:

[role='no_copy']
```
NAME                      SHORTNAMES         APIGROUP              NAMESPACED   KIND
openlibertyapplications   olapp,olapps       apps.openliberty.io   true         OpenLibertyApplication
openlibertydumps          oldump,oldumps     apps.openliberty.io   true         OpenLibertyDump
openlibertytraces         oltrace,oltraces   apps.openliberty.io   true         OpenLibertyTrace
```

Each CRD defines a kind of object that can be used, which is specified in the previous example by the `KIND` value. The `SHORTNAME` value specifies alternative names that you can substitute in the configuration to refer to an object kind. For example, you can refer to the `OpenLibertyApplication` object kind by one of its specified shortnames, such as `olapps`. 

The `openlibertyapplications` CRD defines a set of configurations for deploying an Open Liberty-based application, including the application image, number of instances, and storage settings. The Open Liberty Operator watches for changes to instances of the `OpenLibertyApplication` object kind and creates Kubernetes resources that are based on the configuration that is defined in the CRD.


// =================================================================================================
// Deploying microservices to Amazon Elastic Container Service for Kubernetes (EKS)
// =================================================================================================

== Deploying microservices to Amazon Elastic Container Service for Kubernetes (EKS)

In this section, you will learn how to deploy microservices in Open Liberty containers to a Kubernetes cluster on EKS. You will build and containerize the `system` microservice, push them to a container registry, and then deploy them to your Kubernetes cluster. 

// =================================================================================================
// Pushing the images to a docker registry
// =================================================================================================

=== Pushing the images to a container registry

Pushing the images to a registry allows the cluster to create pods by using your container images. The registry that you are using is called Amazon Elastic Container Registry (ECR).

Authenticate to the registry using the following command so you can push or pull images using Podman:

Start by running the `get-login` command. The `get-login` command returns the `[password_string]`. The `password-stdin` flag provides the password returned by `get-login`. Replace the `[aws_account_id]` and the `[region]` your account is configured under in the following `sudo podman` command, that is used to authenticate your Podman client.

[role=command]
```
aws ecr get-login-password | sudo podman login --username AWS --password-stdin [aws_account_id].dkr.ecr.[region].amazonaws.com
```

After you are authenticated, create a repository for the instanton container image, in the private Amazon ECR registry.
Next, make a repository to store the `system` image:
[role=command]
```
aws ecr create-repository --repository-name instantonaws/system
```

You will see an output similar to the following:

[source, role="no_copy"]
```
{
    "repository": {
        "repositoryArn": "arn:aws:ecr:us-east-2:439159788015:repository/instantonaws/system",
        "registryId": "439159788015",
        "repositoryName": "instantonaws/system",
        "repositoryUri": "439159788015.dkr.ecr.us-east-2.amazonaws.com/instantonaws/system",
        "createdAt": "2023-07-20T10:30:04-07:00",
    ...
}
```

// Tagging images
Next, you need to tag your container image with the relevant data about your registry:

[role=command]
```
sudo podman tag dev.local/system:1.0-SNAPSHOT [system-repository-uri]:1.0-SNAPSHOT
```

// Pushing images
Finally, push your image to the registry:

[role=command]
```
sudo podman push [system-repository-uri]:1.0-SNAPSHOT
```

// =================================================================================================
// Deploying the microservices
// =================================================================================================

=== Deploying the microservices

Now that your container images are built, deploy them using a Kubernetes resource definition.

A Kubernetes resource definition is a yaml file that contains a description of all your deployments, services, or any other resources that you want to deploy. All resources can also be deleted from the cluster by using the same yaml file that you used to deploy them. The `kubernetes.yaml` resource definition file is provided for you. If you are interested in learning more about the Kubernetes resource definition, check out the https://openliberty.io/guides/kubernetes-intro.html[Deploying microservices to Kubernetes^] guide. We can enable Semeru Cloud Compiler by turning `enable` to `true
 
[role="code_command hotspot", subs="quotes"]
----
#Update the `kubernetes.yaml` file in the `start` directory.#
`kubernetes.yaml`
----

kubernetes.yaml

[source, yaml, linenums, role='code_column']

----
include::finish/kubernetes.yaml[]
----
[role="edit_command_text"]
The [hotspot=18 hotspot=39]`applicationImage` is the name and tag of the container image that you want to use for the container. Update its value to point to your `system` repository URI.


Deploy the application by running the following command:
[role=command]
```
kubectl apply -f kubernetes.yaml
```

When the apps are deployed, run the following command to check the status of your pods:

[role=command]
```
kubectl get pods
```

If all the pods are healthy and running, you see an output similar to the following:
[source, role="no_copy"]
----
NAME                                        READY   STATUS    RESTARTS   AGE
olo-controller-manager-58d7788bd-nk7cc      1/1     Running   0          44m
system-deployment-6d559bbcf9-xt7t6          1/1     Running   0          8m40s
system-semeru-compiler-1-58666f5d56-dmhm8   0/1     Pending   0          2m39s
system-semeru-compiler-1-58666f5d56-hs85x   1/1     Running   0          2m39s
system-semeru-compiler-1-58666f5d56-s2pds   0/1     Pending   0          2m39s
----

The `first` pod refers to the Open Liberty Operator. The `second` one for the microservice we deployed and the `last three` for the three replicas of Semeru Cloud Compiler.

To check the semeru cloud compiler and instanton `deployments`, execute the following command:

[role=command]
```
kubectl get deployments
```
[source, role="no_copy"]
----
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
olo-controller-manager     1/1     1            1           50m
system-deployment          1/1     1            1           14m
system-semeru-compiler-1   1/3     3            1           8m56s
----

=== Making requests to the microservices

Before you can make a request to `[hostname]:31000`, you must modify the security group to allow incoming traffic through ports `31000`. To get the `group-id` of the security group, use the `aws ec2 describe-security-groups` command:
[role=command]
```
aws ec2 describe-security-groups --filters Name=group-name,Values="*eksctl-guide-cluster-cluster-*" --query "SecurityGroups[*].IpPermissions[*].UserIdGroupPairs"
```

You will see an output similar to the following:

[source, role="no_copy"]
```
...
    {
        "Description": "Allow nodes to communicate with each other (all ports)",
        "GroupId": "sg-035c858e1ff9c52f1",
        "UserId": "208872073932"
    },
    {
        "Description": "Allow managed and unmanaged nodes to communicate with each other (all ports)",
        "GroupId": "sg-04a0c50049c10ae54",
        "UserId": "208872073932"
    }
...
```

Copy the value of the `GroupId` which description is "Allow managed and unmanaged nodes to communicate with each other (all ports)". In this example output, the value is `sg-04a0c50049c10ae54`.

Then, add the following rules to the security group to allow incoming traffic through port `31000`. Don't forget to substitute `[security-group-id]` for the `GroupId` in the output of the previous command.

[role=command]
```
aws ec2 authorize-security-group-ingress --protocol tcp --port 31000 --group-id [security-group-id] --cidr 0.0.0.0/0
```

After you finish adding the inbound rules to the security group, you might need to wait a few minutes before you try to access the `system` microservice.

Take note of the `EXTERNAL-IP` in the output of the following command. It is the hostname you will later substitute into `[hostname]`: 
[role=command]
```
kubectl get nodes -o wide
```

Then, `curl` or visit the following URLs to access your microservices, substituting the appropriate hostname:

* `http://[hostname]:31000/system/properties`

This URL returns system properties and the name of the pod in an HTTP header called `X-Pod-Name`. To view the header, you can use the `-I` option in the `curl` when you make a request to `http://[hostname]:31000/system/properties`. 

// =================================================================================================
// Testing microservices that are running on AWS EKS
// =================================================================================================

== Testing microservices that are running on AWS EKS

//File 0
pom.xml
[source, xml, linenums, role='code_column']
----
include::finish/system/pom.xml[]
----

A few tests are included for you to test the basic functionality of the microservices. If a test failure occurs, then you might have introduced a bug into the code. To run the tests, wait for all pods to be in the ready state before you proceed further. The default properties defined in the [hotspot file=0]`pom.xml` file are:

[cols="15, 100", options="header"]
|===
| *Property*                                | *Description*
| [hotspot=cluster file=0]`cluster.ip`                         | IP or hostname for your cluster.
| [hotspot=system-service file=0]`system.kube.service`         | Name of the Kubernetes Service wrapping the `system-service` pods.
| [hotspot=system-node-port file=0]`system.node.port`          | The NodePort of the Kubernetes Service `system-service`, 31000 by default.
|===

Use the following command to run the integration tests against your cluster. Substitute `[hostname]` with the appropriate value:

[role=command]
```
mvn failsafe:integration-test -Dcluster.ip=[hostname]
```

If the tests pass, you see an output for each service similar to the following:

[source, role="no_copy"]
----

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.system.SystemEndpointIT
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.673 sec - in it.io.openliberty.guides.system.SystemEndpointIT

Results:

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
----

// =================================================================================================
// Tear Down
// =================================================================================================

== Tearing down the environment

It is important to clean up your resources when you are finished with the guide so that you do not incur additional charges for ongoing service.

When you no longer need your deployed microservices, you can delete all kubernetes resources by running the `kubectl delete` command:
[role='command']
```
kubectl delete -f kubernetes.yaml
```

Delete the ECR repositories used to store the `system` image:
[role=command]
```
aws ecr delete-repository --repository-name instantonaws/system --force
```

Remove your EKS cluster:
[role=command]
```
eksctl delete cluster --name guide-cluster
```


// =================================================================================================
// finish
// =================================================================================================

== Great work! You're done!

You just deployed two microservices running in Open Liberty to AWS EKS. You also learned how to use the `kubectl` command to deploy your microservices on a kubernetes cluster.

// Multipane
include::{common-includes}/attribution.adoc[subs="attributes"]

// DO NO CREATE ANYMORE SECTIONS AT THIS POINT
// Related guides will be added in automatically here if you included them in ":page-related-guides"
